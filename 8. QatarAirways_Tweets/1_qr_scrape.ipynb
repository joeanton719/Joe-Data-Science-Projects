{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ntscraper import Nitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.knowledgator.com/twitter-sentiment-analysis-in-python-few-lines-of-code-bdabfe2efcfd\n",
    "\n",
    "# Define a scraping function that will returns its results in the table. \n",
    "def get_tweets(\n",
    "    query,\n",
    "    scraper,\n",
    "    mode: str,\n",
    "    instance: str,\n",
    "    size: int=-1,\n",
    "    since: str=None,\n",
    "    until: str=None,\n",
    "    language: str='en') -> pd.DataFrame:\n",
    "  \n",
    "  tweets = scraper.get_tweets(query, \n",
    "                              mode=mode,\n",
    "                              to=query,\n",
    "                              number=size,\n",
    "                              since=since,\n",
    "                              until=until,\n",
    "                              instance=instance,\n",
    "                              language=language)\n",
    "  \n",
    "  \n",
    "  final_tweets = []\n",
    "  \n",
    "  try:\n",
    "    for tweet in tweets['tweets']:\n",
    "      \n",
    "      data = [tweet['link'], \n",
    "              tweet['text'], \n",
    "              tweet['date'], \n",
    "              tweet['stats']['likes'], \n",
    "              tweet['stats']['comments']]\n",
    "      \n",
    "      final_tweets.append(data)\n",
    "\n",
    "  except IndexError:\n",
    "    print(\"IndexError\")\n",
    "    pass\n",
    "    \n",
    "  data = pd.DataFrame(final_tweets, columns = ['link', 'text', 'date', 'Likes', 'Comments'])\n",
    "  \n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance=\"https://nitter.woodland.cafe\"\n",
    "\n",
    "for i, date in enumerate(pd.date_range(start=\"2023-12-17\", end=\"2024-01-01\")):\n",
    "\n",
    "    print(date)\n",
    "\n",
    "    # Initialize scraper library\n",
    "    scraper = Nitter(\n",
    "        log_level=1, \n",
    "        skip_instance_check=True,\n",
    "        # skip_instance_check=False,\n",
    "    )\n",
    "\n",
    "    qrtweets_df = get_tweets(query=\"qrsupport\",\n",
    "                            instance=instance,\n",
    "                            scraper=scraper, \n",
    "                            mode=\"term\",\n",
    "                            since=date.strftime('%Y-%m-%d'),\n",
    "                            until=(date + pd.Timedelta(\"1d\")).strftime('%Y-%m-%d'))\n",
    "\n",
    "    # qrtweets_df.to_csv(f\"qrtweets_2022 rest_{i+1}.csv\", index=False) ### CHANGE FILENAME\n",
    "    print()\n",
    "\n",
    "print()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
