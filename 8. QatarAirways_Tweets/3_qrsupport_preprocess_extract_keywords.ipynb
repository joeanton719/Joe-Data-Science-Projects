{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import warnings\n",
    "import textwrap\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# NLTK packages\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Spacy\n",
    "import spacy\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For better visualizations\n",
    "sns.set(style=\"ticks\", palette=\"muted\", color_codes=True)\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 15\n",
    "plt.rcParams['axes.titlesize'] = 20\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "\n",
    "# downloading corpus\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Remove 'not' from stopword list\n",
    "stopwords.remove('not')\n",
    "\n",
    "# Load the spaCy English model\n",
    "# https://github.com/explosion/spaCy/issues/6498\n",
    "nlp = spacy.load(\"en_core_web_lg\", disable=[\"parser\", 'ner'])\n",
    "# nlp.add_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_text(text):\n",
    "    return textwrap.fill(text, width=85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"qatarairways_tweets_sentiments.csv\", parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Comments</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://twitter.com/juliet_gough/status/174158...</td>\n",
       "      <td>It was fantastic service onboard. I'm so impre...</td>\n",
       "      <td>2023-12-31 22:23:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'label': 'positive', 'score': 0.9895235}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://twitter.com/theamaeestales/status/1741...</td>\n",
       "      <td>@qrsupport is there a problem with your app? I...</td>\n",
       "      <td>2023-12-31 19:51:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'label': 'negative', 'score': 0.7817413}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://twitter.com/rvvaradan/status/174143019...</td>\n",
       "      <td>I have reported the incident. Hoping to get a ...</td>\n",
       "      <td>2023-12-31 12:04:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'label': 'neutral', 'score': 0.6894269}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://twitter.com/ManojKa15016293/status/174...</td>\n",
       "      <td>Not settling dues for more than 3 years . Appr...</td>\n",
       "      <td>2023-12-31 10:19:00+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'label': 'positive', 'score': 0.83495665}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://twitter.com/nkonialidis/status/1741377...</td>\n",
       "      <td>Kindly communicate better about the upcoming r...</td>\n",
       "      <td>2023-12-31 08:34:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'label': 'neutral', 'score': 0.82786304}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://twitter.com/juliet_gough/status/174158...   \n",
       "1  https://twitter.com/theamaeestales/status/1741...   \n",
       "2  https://twitter.com/rvvaradan/status/174143019...   \n",
       "3  https://twitter.com/ManojKa15016293/status/174...   \n",
       "4  https://twitter.com/nkonialidis/status/1741377...   \n",
       "\n",
       "                                                text  \\\n",
       "0  It was fantastic service onboard. I'm so impre...   \n",
       "1  @qrsupport is there a problem with your app? I...   \n",
       "2  I have reported the incident. Hoping to get a ...   \n",
       "3  Not settling dues for more than 3 years . Appr...   \n",
       "4  Kindly communicate better about the upcoming r...   \n",
       "\n",
       "                       date  Likes  Comments hashtags  \\\n",
       "0 2023-12-31 22:23:00+00:00      0         0       []   \n",
       "1 2023-12-31 19:51:00+00:00      0         0       []   \n",
       "2 2023-12-31 12:04:00+00:00      1         3       []   \n",
       "3 2023-12-31 10:19:00+00:00      2         2       []   \n",
       "4 2023-12-31 08:34:00+00:00      1         3       []   \n",
       "\n",
       "                                    sentiment  \n",
       "0   {'label': 'positive', 'score': 0.9895235}  \n",
       "1   {'label': 'negative', 'score': 0.7817413}  \n",
       "2    {'label': 'neutral', 'score': 0.6894269}  \n",
       "3  {'label': 'positive', 'score': 0.83495665}  \n",
       "4   {'label': 'neutral', 'score': 0.82786304}  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65793 entries, 0 to 65792\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype              \n",
      "---  ------     --------------  -----              \n",
      " 0   link       65793 non-null  object             \n",
      " 1   text       65793 non-null  object             \n",
      " 2   date       65793 non-null  datetime64[ns, UTC]\n",
      " 3   Likes      65793 non-null  int64              \n",
      " 4   Comments   65793 non-null  int64              \n",
      " 5   hashtags   65793 non-null  object             \n",
      " 6   sentiment  65793 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Text for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@qrsupport @qatarairways I’m genuinely disappointed that my exist seat that I booked\n",
      "for my 16hrs outward flight tomorrow to LAX was given to another passenger when I\n",
      "only changed the date of my return flight. I’ve been a privilege member for 10+\n",
      "years. Wasn’t offered a solution.\n",
      "\n",
      "@qrsupport @qatarairways I am genuinely disappointed that my exist seat that I booked\n",
      "for my 16hrs outward flight tomorrow to LAX was given to another passenger when I\n",
      "only changed the date of my return flight. I have been a privilege member for 10+\n",
      "years. Was not offered a solution.\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/kootenpv/contractions\n",
    "import contractions\n",
    "\n",
    "eg_str = df.loc[199, 'text']\n",
    "print(wrap_text(eg_str))\n",
    "print()\n",
    "print(wrap_text(contractions.fix(eg_str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@qrsupport @qatarairways I’m genuinely disappointed that my exist seat that I booked\n",
      "for my 16hrs outward flight tomorrow to LAX was given to another passenger when I\n",
      "only changed the date of my return flight. I’ve been a privilege member for 10+\n",
      "years. Wasn’t offered a solution.\n",
      "\n",
      "qrsupport qatarairways genuinely disappointed exist seat booked 16hrs outward flight\n",
      "tomorrow LAX given another passenger changed date return flight privilege member 10+\n",
      "years Was not offered solution\n"
     ]
    }
   ],
   "source": [
    "# Remove stopwords function\n",
    "def remove_sw(text):\n",
    "    tokenized_text = word_tokenize(text)\n",
    "    # Remove stopwords and those words that is of length<=2\n",
    "    processed_text = (word for word in tokenized_text if not word in stopwords and len(word) > 2)\n",
    "\n",
    "    return \" \".join(processed_text)\n",
    "\n",
    "print(wrap_text(eg_str))\n",
    "print()\n",
    "print(wrap_text(remove_sw(contractions.fix(eg_str))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@qrsupport @qatarairways I’m genuinely disappointed that my exist seat that I booked\n",
      "for my 16hrs outward flight tomorrow to LAX was given to another passenger when I\n",
      "only changed the date of my return flight. I’ve been a privilege member for 10+\n",
      "years. Wasn’t offered a solution.\n",
      "\n",
      "qrsupport qatarairways genuinely disappointed exist seat book 16hrs outward flight\n",
      "tomorrow LAX give another passenger change date return flight privilege member 10 +\n",
      "year be not offer solution\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "# https://stackoverflow.com/a/75215495/15937542\n",
    "def lemmatize_pipe(text_col):\n",
    "    \n",
    "    docs = nlp.pipe(text_col)\n",
    "    lemmatized_col = [lemmatize_text_spacy(doc) for doc in docs]\n",
    "\n",
    "    return lemmatized_col\n",
    "\n",
    "\n",
    "def lemmatize_text_spacy(doc):\n",
    "\n",
    "    # Extract lemmatized words\n",
    "    # The word refunded does not get lemmatized, hence adding this special condition\n",
    "    lemmatized_words = (token.lemma_ if token.text != \"refunded\" else \"refund\" for token in doc)\n",
    "\n",
    "    # Join the lemmatized words to form the lemmatized text\n",
    "    lemmatized_text = ' '.join(lemmatized_words)\n",
    "\n",
    "    return lemmatized_text\n",
    "\n",
    "print(wrap_text(eg_str))\n",
    "print()\n",
    "\n",
    "doc=nlp(remove_sw(contractions.fix(eg_str)))\n",
    "print(wrap_text(lemmatize_text_spacy(doc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Comments</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>users</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sntmnt_lbl</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://twitter.com/juliet_gough/status/174158...</td>\n",
       "      <td>It was fantastic service onboard. I'm so impre...</td>\n",
       "      <td>2023-12-31 22:23:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>juliet_gough</td>\n",
       "      <td>fantastic service onboard impressed thank</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.989524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://twitter.com/theamaeestales/status/1741...</td>\n",
       "      <td>@qrsupport is there a problem with your app? I...</td>\n",
       "      <td>2023-12-31 19:51:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>theamaeestales</td>\n",
       "      <td>problem app not login account</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.781741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://twitter.com/rvvaradan/status/174143019...</td>\n",
       "      <td>I have reported the incident. Hoping to get a ...</td>\n",
       "      <td>2023-12-31 12:04:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>rvvaradan</td>\n",
       "      <td>report incident hope get resolution soon</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.689427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://twitter.com/ManojKa15016293/status/174...</td>\n",
       "      <td>Not settling dues for more than 3 years . Appr...</td>\n",
       "      <td>2023-12-31 10:19:00+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>ManojKa15016293</td>\n",
       "      <td>not settle due year appreciate emirates airway...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.834957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://twitter.com/nkonialidis/status/1741377...</td>\n",
       "      <td>Kindly communicate better about the upcoming r...</td>\n",
       "      <td>2023-12-31 08:34:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>nkonialidis</td>\n",
       "      <td>kindly communicate well upcoming rebooking</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.827863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://twitter.com/juliet_gough/status/174158...   \n",
       "1  https://twitter.com/theamaeestales/status/1741...   \n",
       "2  https://twitter.com/rvvaradan/status/174143019...   \n",
       "3  https://twitter.com/ManojKa15016293/status/174...   \n",
       "4  https://twitter.com/nkonialidis/status/1741377...   \n",
       "\n",
       "                                                text  \\\n",
       "0  It was fantastic service onboard. I'm so impre...   \n",
       "1  @qrsupport is there a problem with your app? I...   \n",
       "2  I have reported the incident. Hoping to get a ...   \n",
       "3  Not settling dues for more than 3 years . Appr...   \n",
       "4  Kindly communicate better about the upcoming r...   \n",
       "\n",
       "                       date  Likes  Comments hashtags            users  \\\n",
       "0 2023-12-31 22:23:00+00:00      0         0       []     juliet_gough   \n",
       "1 2023-12-31 19:51:00+00:00      0         0       []   theamaeestales   \n",
       "2 2023-12-31 12:04:00+00:00      1         3       []        rvvaradan   \n",
       "3 2023-12-31 10:19:00+00:00      2         2       []  ManojKa15016293   \n",
       "4 2023-12-31 08:34:00+00:00      1         3       []      nkonialidis   \n",
       "\n",
       "                                        cleaned_text sntmnt_lbl     score  \n",
       "0          fantastic service onboard impressed thank   positive  0.989524  \n",
       "1                      problem app not login account   negative  0.781741  \n",
       "2           report incident hope get resolution soon    neutral  0.689427  \n",
       "3  not settle due year appreciate emirates airway...   positive  0.834957  \n",
       "4         kindly communicate well upcoming rebooking    neutral  0.827863  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (\n",
    "    df.drop_duplicates(subset='text', ignore_index=True)\n",
    "    .assign(\n",
    "        \n",
    "        # Extract usernames\n",
    "        users=lambda x: x['link'].str.extract(r'twitter\\.com/(.*?)/status', expand=False),\n",
    "\n",
    "        # For the `cleaned_text` column, first the `text` undergoes all preprocessing steps such as\n",
    "        # removing user hanldes, urls, remove empty spaces, stopwords, etc.\n",
    "        # Finally, the whole proprocessed `text` column is then inputted into the \n",
    "        # \"lemmatize_pipe\" function to process lemmatization quickly.\n",
    "        cleaned_text=lambda x: lemmatize_pipe(\n",
    "            # lower case\n",
    "            x['text'].str.lower()\n",
    "            \n",
    "            # Remove all userhandles\n",
    "            .str.replace(r'@\\w+', ' ', regex=True)\n",
    "            \n",
    "            # Remove all url links\n",
    "            .str.replace(r'https*.*? *|www\\..*? *|bit\\..*? *', \" \", \n",
    "                         regex=True)\n",
    "\n",
    "            # Apply Contractions function\n",
    "            .apply(contractions.fix)\n",
    "\n",
    "            # Remove everything other characters extept alphabets\n",
    "            .str.replace(r'[^a-z]', ' ', regex=True)\n",
    "\n",
    "            # Remove all extra spaces\n",
    "            .str.replace('\\s+', \" \", regex=True)\n",
    "\n",
    "            # Remove leading and trailing spaces\n",
    "            .str.strip()\n",
    "\n",
    "            # Remove stopwords\n",
    "            .apply(remove_sw)\n",
    "            ),\n",
    "        \n",
    "        # Create new column that contain sentiment label\n",
    "        sntmnt_lbl=lambda x: (x['sentiment']\n",
    "                        .apply(ast.literal_eval)\n",
    "                        .apply(lambda x: x['label'])),\n",
    "\n",
    "        # Create new column that contain score for sentiment label\n",
    "        score=lambda x: (x['sentiment']\n",
    "                        .apply(ast.literal_eval)\n",
    "                        .apply(lambda x: x['score'])),\n",
    "    )\n",
    "    # drop sentiment column\n",
    "    .drop('sentiment', axis=1)\n",
    "\n",
    "    # remove those rows with just empty text after preprocessing\n",
    "    .loc[lambda x:x['cleaned_text'].ne('')]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@qrsupport @qatarairways I’m genuinely disappointed that my exist seat that I booked\n",
      "for my 16hrs outward flight tomorrow to LAX was given to another passenger when I\n",
      "only changed the date of my return flight. I’ve been a privilege member for 10+\n",
      "years. Wasn’t offered a solution.\n",
      "\n",
      "genuinely disappointed exist seat book hrs outward flight tomorrow lax give another\n",
      "passenger change date return flight privilege member year not offer solution\n"
     ]
    }
   ],
   "source": [
    "# Compare original vs final preprocessed text\n",
    "print(wrap_text(eg_str))\n",
    "print()\n",
    "print(wrap_text(df.loc[193, 'cleaned_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword/phrase Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KeyBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8679159a89245edbcaee75d221be7b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/991 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "model = KeyBERT('distilbert-base-nli-mean-tokens')\n",
    "\n",
    "def extract_keywords(texts):\n",
    "\n",
    "    kw_list = model.extract_keywords(\n",
    "        texts,\n",
    "        keyphrase_ngram_range=(1, 2),\n",
    "        stop_words=None,\n",
    "        top_n=5,\n",
    "        use_mmr=True,\n",
    "        diversity=0.7\n",
    "    )\n",
    "\n",
    "    keywords=[\",\".join((k[0] for k in kw_tup)) for kw_tup in kw_list]\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "batch_size=64\n",
    "nbr_of_batches=int(np.ceil(len(df)/batch_size))\n",
    "\n",
    "df_batches = np.array_split(df['cleaned_text'].to_list(), nbr_of_batches)\n",
    "\n",
    "keyword_list=[]\n",
    "\n",
    "for batch in tqdm(df_batches):\n",
    "    keywords_from_batch = extract_keywords(texts=batch)\n",
    "    keyword_list.extend(keywords_from_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['keybert_kw']=keyword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>keybert_kw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fantastic service onboard impressed thank</td>\n",
       "      <td>onboard impressed,fantastic service,impressed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>problem app not login account</td>\n",
       "      <td>not login,app not,problem app,problem,login ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>report incident hope get resolution soon</td>\n",
       "      <td>resolution soon,get resolution,incident hope,r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not settle due year appreciate emirates airway...</td>\n",
       "      <td>airways respect,not settle,airways,due year,em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kindly communicate well upcoming rebooking</td>\n",
       "      <td>upcoming rebooking,rebooking,well upcoming,kin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>not believe slowness cancel flight not inform ...</td>\n",
       "      <td>cancel flight,wait minute,talk live,unacceptab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_text  \\\n",
       "0          fantastic service onboard impressed thank   \n",
       "1                      problem app not login account   \n",
       "2           report incident hope get resolution soon   \n",
       "3  not settle due year appreciate emirates airway...   \n",
       "4         kindly communicate well upcoming rebooking   \n",
       "5  not believe slowness cancel flight not inform ...   \n",
       "\n",
       "                                          keybert_kw  \n",
       "0  onboard impressed,fantastic service,impressed ...  \n",
       "1  not login,app not,problem app,problem,login ac...  \n",
       "2  resolution soon,get resolution,incident hope,r...  \n",
       "3  airways respect,not settle,airways,due year,em...  \n",
       "4  upcoming rebooking,rebooking,well upcoming,kin...  \n",
       "5  cancel flight,wait minute,talk live,unacceptab...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:5, ['cleaned_text', 'keybert_kw']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import yake\n",
    "\n",
    "# Initialize YAKE extractor outside the function for better performance\n",
    "yake_kw = yake.KeywordExtractor(n=2, top=5, windowsSize=100)\n",
    "\n",
    "def yake_extract_kw(text):\n",
    "    try:\n",
    "        # Extracting keywords \n",
    "        KeyWords = yake_kw.extract_keywords(text) \n",
    "\n",
    "        # Displaying top 5 keywords \n",
    "        keywords = \",\".join((kw for kw, _ in KeyWords if \"qatar\" not in kw))\n",
    "        return keywords\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {text}\")\n",
    "        print(f\"Error details: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# https://stackoverflow.com/questions/42220458/what-does-the-delayed-function-do-when-used-with-joblib-in-python\n",
    "def process_texts_parallel(texts, n_jobs=-1):\n",
    "    results = Parallel(n_jobs=n_jobs)(delayed(yake_extract_kw)(text) for text in texts)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yake_kw']=process_texts_parallel(df['cleaned_text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df\n",
    "#  .drop('keybwet_kw', axis=1)\n",
    " .to_csv(\"qatarairways_tweets_sentiments_with_keywords.csv\", index=False)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
